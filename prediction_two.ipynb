{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Footy tipping! Part IV\n",
    "\n",
    "Adding features to improve the logistic/SVM models\n",
    "+ polynomial -- this is not helping\n",
    "+ adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in training data\n",
    "data_train = pd.read_csv('afl_train.csv')\n",
    "# drop if year 2005\n",
    "data_train = data_train.drop(data_train[data_train.season==2000].index)\n",
    "data_train.fillna(0)\n",
    "# make X, y variables\n",
    "X = data_train[['home_percentage', 'away_percentage', \n",
    "                       'home_last_season_percentage', 'away_last_season_percentage']].as_matrix()\n",
    "y = data_train[['home_team_win']].as_matrix()\n",
    "m, n = X.shape\n",
    "X_cols = ['home_percentage', 'away_percentage', \n",
    "                       'home_last_season_percentage', 'away_last_season_percentage']\n",
    "y_col = ['home_team_win']\n",
    "\n",
    "# load in cross validation data\n",
    "data_train = pd.read_csv('afl_cval.csv')\n",
    "X_cv = data_train[['home_percentage', 'away_percentage', \n",
    "                       'home_last_season_percentage', 'away_last_season_percentage']].as_matrix()\n",
    "y_cv = data_train[['home_team_win']].as_matrix()\n",
    "m_cv, n_cv = X.shape\n",
    "X_cols_cv = ['home_percentage', 'away_percentage', \n",
    "                       'home_last_season_percentage', 'away_last_season_percentage']\n",
    "y_col_cv = ['home_team_win']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the features polynomial\n",
    "\n",
    "Restricted so that each feature has the same order polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly_features(X_0, p):\n",
    "    X = np.ones((X_0.shape[0], p))\n",
    "    X[:,0] = X_0.flatten()\n",
    "    for j in range(1, p):\n",
    "        X[:,j] = X[:,0]**(j+1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def poly_wrapper(X, p):\n",
    "    \"\"\"\n",
    "    A wrapper to create polynomials for multiple features\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    df = poly_features(X[:,0], p)\n",
    "    for i in range(1,n):\n",
    "        df1 = poly_features(X[:,i], p)\n",
    "        df = np.concatenate((df, df1), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_normalise(X_0):\n",
    "    X_p = np.zeros(X_0.shape)\n",
    "    mu = []\n",
    "    sigma = []\n",
    "    for j in range(0, X_0.shape[1]):\n",
    "        mean_j = np.mean(X_0[:,j])\n",
    "        std_j = np.std(X_0[:,j])\n",
    "        X_p[:,j] = (( X_0[:,j] - mean_j) / std_j)\n",
    "        mu.append(mean_j)\n",
    "        sigma.append(std_j)\n",
    "    return X_p, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Logistic regression\n",
    "\n",
    "We get a slight increase in performance. No change to bias nor variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66060606060606064"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "pred_log = log_reg.fit(X, y.ravel())\n",
    "pred_log.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 3\n",
    "X_p, mu, sig = feature_normalise(poly_wrapper(X, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66573426573426575"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "pred_log = log_reg.fit(X_p, y.ravel())\n",
    "pred_log.score(X_p, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70707070707070707"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv_p, mu, sig = feature_normalise(poly_wrapper(X_cv, p))\n",
    "pred_log.score(X_cv_p, y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###SVM time\n",
    "\n",
    "With p = 5, the variance is high.\n",
    "With p = 2, the results are identical.\n",
    "\n",
    "Feature normalisation helps a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=1,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf', gamma=1, C=0.5)\n",
    "clf.fit(X_p, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74405594405594411"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_p, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66666666666666663"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_cv_p, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
